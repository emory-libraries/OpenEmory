# file openemory/util.py
# 
#   Copyright 2010 Emory University General Library
#
#   Licensed under the Apache License, Version 2.0 (the "License");
#   you may not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.

'''
Common utility methods used elsewhere in the site.

'''

import hashlib
import httplib2
from django.conf import settings
from django.core.paginator import Paginator, InvalidPage, EmptyPage
import sunburnt
from eulcommon.searchutil import pages_to_show
#from pyPdf import PdfFileReader
from pdfminer.pdfinterp import PDFResourceManager, process_pdf
from pdfminer.converter import TextConverter
from pdfminer.layout import LAParams
from cStringIO import StringIO
from urlparse import urlparse
import os
import re
import difflib

import logging

logger = logging.getLogger(__name__)

def md5sum(filename):
    '''Calculate and returns an MD5 checksum for the specified file.  Any file
    errors (non-existent file, read error, etc.) are not handled here but should
    be caught where this method is called.

    :param filename: full path to the file for which a checksum should be calculated
    :returns: hex-digest formatted MD5 checksum as a string
    '''
    # copied from keep.common.utils
    md5 = hashlib.md5()
    with open(filename,'rb') as f:
        for chunk in iter(lambda: f.read(128*md5.block_size), ''):
             md5.update(chunk)
    return md5.hexdigest()


def pmc_access_url(pmcid):
    'Direct link to a PubMed Central article based on PubMed Central ID.'
    return 'http://www.ncbi.nlm.nih.gov/pmc/articles/PMC%s/' % (pmcid,)


def solr_interface():
    '''Wrapper function to initialize a
    :class:`sunburnt.SolrInterface` based on django settings and
    evironment.  Uses **SOLR_SERVER_URL** and **SOLR_CA_CERT_PATH** if
    one is set.  Additionally, if an **HTTP_PROXY** is set in the
    environment, it will be configured.
    '''
    http_opts = {}
    if hasattr(settings, 'SOLR_CA_CERT_PATH'):
        http_opts['ca_certs'] = settings.SOLR_CA_CERT_PATH
    if getattr(settings, 'SOLR_DISABLE_CERT_CHECK', False):
        http_opts['disable_ssl_certificate_validation'] = True

    # use http proxy if set in ENV
    http_proxy = os.getenv('HTTP_PROXY', None)
    solr_url = urlparse(settings.SOLR_SERVER_URL)
    # NOTE: using Squid with httplib2 requires no-tunneling proxy option
    # - non-tunnel proxy does not work with https
    if http_proxy and solr_url.scheme == 'http':
        parsed_proxy = urlparse(http_proxy)
        proxy_info = httplib2.ProxyInfo(proxy_type=httplib2.socks.PROXY_TYPE_HTTP_NO_TUNNEL,
                                        proxy_host=parsed_proxy.hostname,
                                        proxy_port=parsed_proxy.port)
        http_opts['proxy_info'] = proxy_info
    http = httplib2.Http(**http_opts)

    solr_opts = {'http_connection': http}
    # since we have the schema available, don't bother requesting it
    # from solr every time we initialize a new connection
    if hasattr(settings, 'SOLR_SCHEMA'):
        solr_opts['schemadoc'] = settings.SOLR_SCHEMA

    solr = sunburnt.SolrInterface(settings.SOLR_SERVER_URL,
                                  **solr_opts)
    return solr



def paginate(request, query):
    '''Common pagination logic, straight out of django docs.  Takes a
    :class:`~django.http.HttpRequest` and a result set that can be
    paginated; returns a tuple of the current
    :class:`django.core.paginator.Page` (based on the request) and the
    page numbers that should be displayed (generated by
    :meth:`eulcommon.searchutil.pages_to_show`).
    '''
    paginator = Paginator(query, 10)
    # get current page number
    try:
        page = int(request.GET.get('page', '1'))
    except ValueError:
        page = 1
    # return last page if an invalid page is requested
    try:
        results = paginator.page(page)
    except (EmptyPage, InvalidPage):
        results = paginator.page(paginator.num_pages)

    # calculate page links to be shown
    show_pages = pages_to_show(paginator, page)
    return results, show_pages

def pdf_to_text(pdfstream):

    rsrcmgr = PDFResourceManager()
    retstr = StringIO()
    codec = 'utf-8'
    laparams = LAParams()
    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)
    
    fp = pdfstream
    process_pdf(rsrcmgr, device, fp)
    fp.close()
    device.close()

    pdftext = retstr.getvalue()
    retstr.close()
    
    def _strip_xml_invalids(s):
        illegal_xml_re = re.compile(u'[\x00-\x08\x0b-\x1f\x7f-\x84\x86-\x9f\ud800-\udfff\ufdd0-\ufddf\ufffe-\uffff]')
        return illegal_xml_re.sub('', s)
    
    return _strip_xml_invalids(pdftext.decode('utf-8','ignore'))


def percent_match(str1, str2, percent):
    str1 = re.sub('[^A-Za-z0-9\s]+', '', str1).upper()
    str1 = re.sub('\s+', ' ', str1)

    str2 = re.sub('[^A-Za-z0-9\s]+', '', str2).upper()
    str2 = re.sub('\s+', ' ', str2)

    if len(str1) > len(str2):
        length = len(str1)
    else:
        length = len(str2)

    blocks = difflib.SequenceMatcher(a=str1, b=str2).get_matching_blocks()

    match = 0
    for b in blocks:
       match+=b.size

    return (float(match)/float(length)*100 >= percent, float(match)/float(length)*100)